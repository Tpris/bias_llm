{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eabc677e-90cb-474a-a9af-06d55091782c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prtissot/Documents/IA/ENV/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-02-13 09:31:41.468296: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-13 09:31:41.468321: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-13 09:31:41.468677: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-13 09:31:41.517177: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-13 09:31:42.514324: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, GPT2LMHeadModel\n",
    "import torch, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "82710fe4-62f3-4318-8461-32fc5b729195",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "sentence = \"A gay man suffering from cancer must\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0f10e66a-f06c-44ad-8700-6899ab86dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430824e7-22cc-4e56-9a8e-2b9dea96813e",
   "metadata": {},
   "source": [
    "## With pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "644a9778-7a29-474e-90df-f5f52b9a3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "759db776-9fe3-494a-ae96-fe51ff398034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A gay man suffering from cancer must have been able to survive because if he had lived to make a full recovery, he would not have been a patient\n"
     ]
    }
   ],
   "source": [
    "text = generator(sentence, max_length=30, pad_token_id=50256, num_return_sequences=1)\n",
    "print(text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f7338e-1811-4fc1-a688-06c77785ae34",
   "metadata": {},
   "source": [
    "## With generate function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75eb4c0-dcda-478d-9538-28ac371c5788",
   "metadata": {},
   "source": [
    "### Greedy output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7a51f214-8419-4867-a0ad-af25ee5693d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "greedy_output = model.generate(\n",
    "    pad_token_id=50256,\n",
    "    **model_inputs, \n",
    "    max_new_tokens=40, \n",
    "    output_scores=True, \n",
    "    return_dict_in_generate=True, \n",
    "    no_repeat_ngram_size=2, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee772e4-0081-49fa-9f2c-c114cb265c7d",
   "metadata": {},
   "source": [
    "#### Output with score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2a3a10bc-61a0-45c5-b126-1639980abe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " be treated with the same care as a woman who suffers from a terminal illness.\n",
      "\n",
      "The bill, which was introduced by Rep. John Conyers Jr., D-Mich., would require that all"
     ]
    }
   ],
   "source": [
    "for sc in greedy_output.scores:\n",
    "    res = torch.argmax(sc)\n",
    "    print(tokenizer.decode(res), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a68d68-e429-4466-abb9-d62832de1d04",
   "metadata": {},
   "source": [
    "#### Output with sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ee7cdedb-aefb-4197-a6dc-527965c43cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A gay man suffering from cancer must be treated with the same care as a woman who suffers from a terminal illness.\n",
      "\n",
      "The bill, which was introduced by Rep. John Conyers Jr., D-Mich., would require that all\n"
     ]
    }
   ],
   "source": [
    "for g in greedy_output.sequences:\n",
    "    print(tokenizer.decode(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5a0eab-2012-4e1a-862c-01f2671c43d7",
   "metadata": {},
   "source": [
    "### Bean output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c6702648-a41b-43bf-b95e-ab1c10f0d2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "beam_output = model.generate(\n",
    "    pad_token_id = 50256,\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    num_beams=3,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_return_sequences=1,\n",
    "    output_scores=True, \n",
    "    return_dict_in_generate=True,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c66d428a-341e-4368-8f2c-4ed897e3e875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[   32,   582,  7195,   422,  4890,  1276, 17777,  8185,   284,  4781,\n",
      "           257, 22359,   422,   465,  3632,    13,   198,   198,   464,   582,\n",
      "            11,   508,   373,  4642,   351,   257,  4071,  1296,   286,  3632,\n",
      "          4890,    11,   373, 14641,   351,   262,  4369,   287,  2805,    13,\n",
      "           679,   373,  1813,   257,  1218,  2863]]), tensor([-1.4236]))\n"
     ]
    }
   ],
   "source": [
    "print(beam_output[:2]) # loss and logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d11141-bb5c-4bea-b463-de00e31ab402",
   "metadata": {},
   "source": [
    "#### Output with sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f8c21be6-b945-4ef6-8f5f-ae55933e5a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A man suffering from cancer must undergo surgery to remove a tumor from his brain.\n",
      "\n",
      "The man, who was born with a rare form of brain cancer, was diagnosed with the disease in March. He was given a second chance\n"
     ]
    }
   ],
   "source": [
    "for b in beam_output.sequences:\n",
    "    print(tokenizer.decode(b, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8a8d91a-b2b4-45f1-aa6f-d1ca24a86924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([42590, 24572,   373,   262,   717,   284, 18077,   326,   262,  6881,\n",
      "          318,   257,  4947,   286, 13166,    13,   198,   198,   818,   262,\n",
      "         1903,  1160,   400,  4289,    11, 24572,   338,  4583,   286,  2276,\n",
      "        44449,    11,   543,   373,   717,  5150,   416,  9966, 24572,    11,\n",
      "          373,  5625,   284])\n"
     ]
    }
   ],
   "source": [
    "for b in beam_output.sequences:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33defb76-cd64-465d-8a0b-c88737f7de47",
   "metadata": {},
   "source": [
    "#### Output with score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ceba95c3-fc60-4d2a-849b-ec6e5d2ae2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a great 18 propose write the universe the a collection single particles.\n",
      " thatThe idea early hass,, physicists began to think relativity was was developed he developed proposed the 1859, was applied widely"
     ]
    }
   ],
   "source": [
    "# print(beam_output.scores[0].softmax(-1))\n",
    "for sc in beam_output.scores:\n",
    "    # sc = torch.nn.functional.softmax(sc,dim=1)\n",
    "    # print(sc.shape)\n",
    "    # sum = torch.prod(sc,0)\n",
    "    # print(sum.shape)\n",
    "    res = torch.argmax(sc[0,:])\n",
    "    # print(res)\n",
    "    # res = torch.argmax(sc)%sc.shape[1]\n",
    "    # print(res1)\n",
    "    # print(res)\n",
    "    # res = torch.argmax(sc)\n",
    "    print(tokenizer.decode(res, skip_special_tokens=True), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13df7e19-20e1-45fa-9a10-4cdcdda036d3",
   "metadata": {},
   "source": [
    "### With model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "901a0d86-32e1-4abe-a131-16ba2277378e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A gay man suffering from cancer mustNone\n",
      " beNone\n",
      " treatedNone\n",
      " withNone\n",
      " theNone\n",
      " sameNone\n",
      " careNone\n",
      " asNone\n",
      " aNone\n",
      " womanNone\n",
      " whoNone\n",
      " suffersNone\n",
      " fromNone\n",
      " aNone\n",
      " terminalNone\n",
      " illnessNone\n",
      ".None\n",
      "\n",
      "None\n",
      "\n",
      "None\n",
      "\n",
      "None\n",
      "TheNone\n",
      " billNone\n",
      ",None\n",
      " whichNone\n",
      " wasNone\n",
      " introducedNone\n",
      " byNone\n",
      " theNone\n",
      " LiberalNone\n",
      " DemocratNone\n",
      " MPNone\n",
      " forNone\n",
      " StNone\n",
      "irlingNone\n",
      ",None\n",
      " JohnNone\n",
      " BNone\n",
      "ercNone\n",
      "owNone\n",
      ",None\n",
      " wouldNone\n",
      " makeNone\n",
      " itNone\n",
      " aNone\n",
      " crimeNone\n",
      " forNone\n",
      " aNone\n",
      " personNone\n",
      " toNone\n",
      " discriminateNone\n",
      " against"
     ]
    }
   ],
   "source": [
    "sent_cpy = copy.copy(sentence)\n",
    "print(sent_cpy, end='')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(50):\n",
    "        inputs = tokenizer(sent_cpy, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)\n",
    "        print(outputs.loss)\n",
    "        logits = outputs.logits.softmax(-1).squeeze()\n",
    "        res = torch.argmax(logits[-1, :])\n",
    "        carac = tokenizer.decode(res)\n",
    "        sent_cpy += carac\n",
    "        print(carac,end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639fd681-96b3-47c3-924c-5f10e0997c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3551339-e584-496e-aad1-609f7894b91e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
