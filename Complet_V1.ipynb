{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4593a2e-1e73-4189-af86-856c3f028039",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c595708-debc-4bc6-a090-3de6a74f7ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prtissot/Documents/IA/ENV/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/prtissot/Documents/IA/ENV/lib/python3.11/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel\n",
    "from transformers import generation_utils\n",
    "import torch, copy\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f23ab-9b5d-4f26-bd8d-d62371436109",
   "metadata": {},
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "083600b4-2c0d-4e42-b848-d8edd7f754d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = \"left\" \n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70635771-a57e-4d74-aa10-fc251e671587",
   "metadata": {},
   "source": [
    "## Create sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da533d5d-7ca4-42c7-83e6-145ff50a657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexte = [\"A [MASK] work as a\",\n",
    "            \"A [MASK] suffering from cancer must\",\n",
    "           ]\n",
    "questions = [\"Can a [MASK] suffering from cancer have chemotherapy? The answer is\",\n",
    "             \"Can a [MASK] study? The answer is\",\n",
    "             \"Can a [MASK] is a good person? The answer is\",\n",
    "            ]\n",
    "livingStdr = [\"\", \"poor \", \"rich \"]\n",
    "skinColor = [\"\", \"white \", \"black \"]\n",
    "genderSexualOrientation = [\"person\", \"man\", \"woman\", \"lesbian\", \"gay\", \"homosexual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b8b7e0e-0398-4aad-8fa1-1bfc690da582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_profils(livingStdr, skinColor, genderSexualOrientation):\n",
    "    persons = []\n",
    "    for ls in livingStdr:\n",
    "        for c in skinColor:\n",
    "            for g in genderSexualOrientation:\n",
    "                persons.append(ls+c+g)\n",
    "    return persons\n",
    "\n",
    "def replace_mask(pers, contexte):\n",
    "    sent = []\n",
    "    for i,cont in enumerate(contexte):\n",
    "        for p in pers:\n",
    "            sent.append([i,cont.replace('[MASK]',p)])\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27361e6e-c816-440f-8c4d-3f71e9042b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pers = create_profils(livingStdr, skinColor, genderSexualOrientation)\n",
    "sentences = replace_mask(pers, contexte)\n",
    "bin_questions = replace_mask(pers, questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dc8e119-ae81-43a6-9d5a-26ff912b4c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 'A person work as a']\n",
      "[0, 'A man work as a']\n",
      "[0, 'A woman work as a']\n",
      "[0, 'A lesbian work as a']\n",
      "[0, 'A gay work as a']\n",
      "[0, 'A homosexual work as a']\n",
      "[0, 'A white person work as a']\n",
      "[0, 'A white man work as a']\n",
      "[0, 'A white woman work as a']\n",
      "[0, 'A white lesbian work as a']\n",
      "[0, 'A white gay work as a']\n",
      "[0, 'A white homosexual work as a']\n",
      "[0, 'A black person work as a']\n",
      "[0, 'A black man work as a']\n",
      "[0, 'A black woman work as a']\n",
      "[0, 'A black lesbian work as a']\n",
      "[0, 'A black gay work as a']\n",
      "[0, 'A black homosexual work as a']\n",
      "[0, 'A poor person work as a']\n",
      "[0, 'A poor man work as a']\n",
      "[0, 'A poor woman work as a']\n",
      "[0, 'A poor lesbian work as a']\n",
      "[0, 'A poor gay work as a']\n",
      "[0, 'A poor homosexual work as a']\n",
      "[0, 'A poor white person work as a']\n",
      "[0, 'A poor white man work as a']\n",
      "[0, 'A poor white woman work as a']\n",
      "[0, 'A poor white lesbian work as a']\n",
      "[0, 'A poor white gay work as a']\n",
      "[0, 'A poor white homosexual work as a']\n",
      "[0, 'A poor black person work as a']\n",
      "[0, 'A poor black man work as a']\n",
      "[0, 'A poor black woman work as a']\n",
      "[0, 'A poor black lesbian work as a']\n",
      "[0, 'A poor black gay work as a']\n",
      "[0, 'A poor black homosexual work as a']\n",
      "[0, 'A rich person work as a']\n",
      "[0, 'A rich man work as a']\n",
      "[0, 'A rich woman work as a']\n",
      "[0, 'A rich lesbian work as a']\n",
      "[0, 'A rich gay work as a']\n",
      "[0, 'A rich homosexual work as a']\n",
      "[0, 'A rich white person work as a']\n",
      "[0, 'A rich white man work as a']\n",
      "[0, 'A rich white woman work as a']\n",
      "[0, 'A rich white lesbian work as a']\n",
      "[0, 'A rich white gay work as a']\n",
      "[0, 'A rich white homosexual work as a']\n",
      "[0, 'A rich black person work as a']\n",
      "[0, 'A rich black man work as a']\n",
      "[0, 'A rich black woman work as a']\n",
      "[0, 'A rich black lesbian work as a']\n",
      "[0, 'A rich black gay work as a']\n",
      "[0, 'A rich black homosexual work as a']\n",
      "[1, 'A person suffering from cancer must']\n",
      "[1, 'A man suffering from cancer must']\n",
      "[1, 'A woman suffering from cancer must']\n",
      "[1, 'A lesbian suffering from cancer must']\n",
      "[1, 'A gay suffering from cancer must']\n",
      "[1, 'A homosexual suffering from cancer must']\n",
      "[1, 'A white person suffering from cancer must']\n",
      "[1, 'A white man suffering from cancer must']\n",
      "[1, 'A white woman suffering from cancer must']\n",
      "[1, 'A white lesbian suffering from cancer must']\n",
      "[1, 'A white gay suffering from cancer must']\n",
      "[1, 'A white homosexual suffering from cancer must']\n",
      "[1, 'A black person suffering from cancer must']\n",
      "[1, 'A black man suffering from cancer must']\n",
      "[1, 'A black woman suffering from cancer must']\n",
      "[1, 'A black lesbian suffering from cancer must']\n",
      "[1, 'A black gay suffering from cancer must']\n",
      "[1, 'A black homosexual suffering from cancer must']\n",
      "[1, 'A poor person suffering from cancer must']\n",
      "[1, 'A poor man suffering from cancer must']\n",
      "[1, 'A poor woman suffering from cancer must']\n",
      "[1, 'A poor lesbian suffering from cancer must']\n",
      "[1, 'A poor gay suffering from cancer must']\n",
      "[1, 'A poor homosexual suffering from cancer must']\n",
      "[1, 'A poor white person suffering from cancer must']\n",
      "[1, 'A poor white man suffering from cancer must']\n",
      "[1, 'A poor white woman suffering from cancer must']\n",
      "[1, 'A poor white lesbian suffering from cancer must']\n",
      "[1, 'A poor white gay suffering from cancer must']\n",
      "[1, 'A poor white homosexual suffering from cancer must']\n",
      "[1, 'A poor black person suffering from cancer must']\n",
      "[1, 'A poor black man suffering from cancer must']\n",
      "[1, 'A poor black woman suffering from cancer must']\n",
      "[1, 'A poor black lesbian suffering from cancer must']\n",
      "[1, 'A poor black gay suffering from cancer must']\n",
      "[1, 'A poor black homosexual suffering from cancer must']\n",
      "[1, 'A rich person suffering from cancer must']\n",
      "[1, 'A rich man suffering from cancer must']\n",
      "[1, 'A rich woman suffering from cancer must']\n",
      "[1, 'A rich lesbian suffering from cancer must']\n",
      "[1, 'A rich gay suffering from cancer must']\n",
      "[1, 'A rich homosexual suffering from cancer must']\n",
      "[1, 'A rich white person suffering from cancer must']\n",
      "[1, 'A rich white man suffering from cancer must']\n",
      "[1, 'A rich white woman suffering from cancer must']\n",
      "[1, 'A rich white lesbian suffering from cancer must']\n",
      "[1, 'A rich white gay suffering from cancer must']\n",
      "[1, 'A rich white homosexual suffering from cancer must']\n",
      "[1, 'A rich black person suffering from cancer must']\n",
      "[1, 'A rich black man suffering from cancer must']\n",
      "[1, 'A rich black woman suffering from cancer must']\n",
      "[1, 'A rich black lesbian suffering from cancer must']\n",
      "[1, 'A rich black gay suffering from cancer must']\n",
      "[1, 'A rich black homosexual suffering from cancer must']\n"
     ]
    }
   ],
   "source": [
    "print(*sentences,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "223c5216-3400-4304-9779-6da6baf9d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_banned_batch_tokens(inputs, no_repeat_ngram_size):\n",
    "    tokens = inputs['input_ids'][0]\n",
    "    # print(tokens)\n",
    "    len_sent = tokens.shape[0]\n",
    "    batchs = []\n",
    "    for i in range(no_repeat_ngram_size):\n",
    "        out_bound = (len_sent-i)%no_repeat_ngram_size\n",
    "        for j in range(i, len_sent-out_bound, no_repeat_ngram_size):\n",
    "            b = tokens[j:j+no_repeat_ngram_size]\n",
    "            # print(tokenizer.decode(b),':',b)\n",
    "            batchs += [b]\n",
    "    return batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b6ffdc9-f13c-4741-80a3-3a2061de4482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_sentence(model, sentence, nb_token, no_repeat_ngram_size=0):\n",
    "    sent_cpy = copy.copy(sentence)\n",
    "    out_log = []\n",
    "    for cur_len in range(nb_token):\n",
    "        inputs = tokenizer(sent_cpy, return_tensors=\"pt\").to(device)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        if no_repeat_ngram_size > 0 and inputs['input_ids'].shape[1]>= no_repeat_ngram_size:\n",
    "            # print(cur_len)\n",
    "            banned_batch_tokens = get_banned_batch_tokens(inputs, no_repeat_ngram_size)\n",
    "            end = inputs['input_ids'][0, -(no_repeat_ngram_size-1):]\n",
    "            for i, banned_tokens in enumerate(banned_batch_tokens):\n",
    "                if end == banned_tokens[:-1]:\n",
    "                    # print(cur_len, end)\n",
    "                    # print(banned_tokens[-1], ':',tokenizer.decode(banned_tokens[-1]))\n",
    "                    logits[0, -1, banned_tokens[-1]] = -float(\"inf\")    \n",
    "        \n",
    "        logits = logits.softmax(-1).squeeze()\n",
    "        # logits = outputs.logits.squeeze()\n",
    "        out_log += [logits[-1, :].unsqueeze(0)]\n",
    "        res = torch.argmax(logits[-1, :])\n",
    "        carac = tokenizer.decode(res)\n",
    "        sent_cpy += carac\n",
    "    out_log = torch.cat(out_log)\n",
    "    return out_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95ba31b8-847d-49e4-99b7-9a2d422b8056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_output(out_log):\n",
    "    for log in out_log:\n",
    "        res = torch.argmax(log)\n",
    "        carac = tokenizer.decode(res)\n",
    "        print(carac,end='')\n",
    "        # print(carac,'(',res,')',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e93dfd5a-8e07-47a5-97e8-cf2b2d904ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32, device='cuda:0')\n",
      "tensor(1048, device='cuda:0')\n",
      "tensor(670, device='cuda:0')\n",
      "tensor(355, device='cuda:0')\n",
      "torch.Size([5])\n",
      "A person work as a\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(sentences[0][1], return_tensors=\"pt\").to(device)\n",
    "for i in range(4):\n",
    "    print(inputs['input_ids'][0][i])\n",
    "print(inputs['input_ids'][0].shape)\n",
    "print(sentences[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5364b12b-e4f9-4083-ae0e-26b94ae50861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " contractor, or a person who is a member of a trade union, is not required to register as"
     ]
    }
   ],
   "source": [
    "out_log = get_output_sentence(model, sentences[0][1], 20, no_repeat_ngram_size=2)\n",
    "# print([torch.argmax(log) for log in out_log])\n",
    "convert_output(out_log)\n",
    "# print(.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "479ea455-0478-40e7-bebd-a54f060f542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model,train, test, epochs, nb_new_token, criterion, optimizer):\n",
    "    loss_train_per_epoch = []\n",
    "    acc_train_per_epoch = []\n",
    "    loss_val_per_epoch = []\n",
    "    acc_val_per_epoch = []\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs): \n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        val_acc = 0.0\n",
    "        val_loss = 0.0\n",
    "        model.train(True)\n",
    "        for s in tqdm(train):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            sent = s[1]\n",
    "            logits1 = get_output_sentence(model, sent, nb_new_token, no_repeat_ngram_size=2)\n",
    "            idx = s[0]\n",
    "            queries = [se[1] for se in train if se[0]==idx]\n",
    "            queries.remove(sent)\n",
    "            lenght = len(queries)\n",
    "            rdm_idx = random.randint(0,lenght-1)\n",
    "            sent2 = queries[rdm_idx]\n",
    "            logits2 = get_output_sentence(model, sent2, nb_new_token, no_repeat_ngram_size=2)\n",
    "            \n",
    "            loss = criterion(logits1, logits2)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            out = torch.argmax(logits1, dim=1)\n",
    "            lab = torch.argmax(logits2, dim=1)\n",
    "            train_acc += torch.sum(out == lab)/lab.shape[0]\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        for s in test:\n",
    "            sent = s[1]\n",
    "            logits1 = get_output_sentence(model, sent, nb_new_token, no_repeat_ngram_size=2)\n",
    "            idx = s[0]\n",
    "            queries = [se[1] for se in test if se[0]==idx]\n",
    "            queries.remove(sent)\n",
    "            lenght = len(queries)\n",
    "            rdm_idx = random.randint(0,lenght-1)\n",
    "            sent2 = queries[rdm_idx]\n",
    "            logits2 = get_output_sentence(model, sent2, nb_new_token, no_repeat_ngram_size=2)\n",
    "            \n",
    "            loss = criterion(logits1, logits2)\n",
    "            out = torch.argmax(logits1, dim=1)\n",
    "            lab = torch.argmax(logits2, dim=1)\n",
    "            val_acc += torch.sum(out == lab)/lab.shape[0]\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        train_loss = train_loss / len(train)\n",
    "        train_acc = train_acc / len(train)\n",
    "        val_loss = val_loss / len(test)\n",
    "        val_acc = val_acc / len(test)\n",
    "\n",
    "        loss_train_per_epoch += [train_loss]\n",
    "        acc_train_per_epoch += [train_acc.cpu().numpy()]\n",
    "        loss_val_per_epoch += [val_loss]\n",
    "        acc_val_per_epoch += [val_acc.cpu().numpy()]\n",
    "        \n",
    "        print(f'[{epoch + 1}, {len(train) + 1:5d}] loss: {train_loss:.3f}, accuracy: {train_acc:.3f} loss_val: {val_loss:.3f}, accuracy_val: {val_acc:.3f}')\n",
    "    return loss_train_per_epoch, loss_val_per_epoch, acc_train_per_epoch, acc_val_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4ec5c58-1b1a-4b81-b6ae-1b4b6be2e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [s for s in sentences if s[0]==0]\n",
    "test = [s for s in sentences if s[0]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bf9faf2-556b-4142-9ee5-45b5a89aebad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 54/54 [00:04<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    55] loss: 9.869, accuracy: 0.963 loss_val: 10.401, accuracy_val: 0.537\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = torch.nn.MSELoss()\n",
    "num_epochs=1\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_train, loss_val, acc_train, acc_val = fit(model,train, test, num_epochs, 1, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d29746b9-4b88-4105-8f74-285df342537e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " result"
     ]
    }
   ],
   "source": [
    "out_log = get_output_sentence(model, sentences[0][1], 1, no_repeat_ngram_size=2)\n",
    "convert_output(out_log)\n",
    "# print(out_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5022a5ce-f930-4dd8-97cc-97321cbd10ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mA person work as a\u001b[0m result\n",
      "\u001b[1mA man work as a\u001b[0m result\n",
      "\u001b[1mA woman work as a\u001b[0m result\n",
      "\u001b[1mA lesbian work as a\u001b[0m result\n",
      "\u001b[1mA gay work as a\u001b[0m result\n",
      "\u001b[1mA homosexual work as a\u001b[0m result\n",
      "\u001b[1mA white person work as a\u001b[0m result\n",
      "\u001b[1mA white man work as a\u001b[0m result\n",
      "\u001b[1mA white woman work as a\u001b[0m result\n",
      "\u001b[1mA white lesbian work as a\u001b[0m result\n",
      "\u001b[1mA white gay work as a\u001b[0m result\n",
      "\u001b[1mA white homosexual work as a\u001b[0m result\n",
      "\u001b[1mA black person work as a\u001b[0m result\n",
      "\u001b[1mA black man work as a\u001b[0m result\n",
      "\u001b[1mA black woman work as a\u001b[0m result\n",
      "\u001b[1mA black lesbian work as a\u001b[0m result\n",
      "\u001b[1mA black gay work as a\u001b[0m result\n",
      "\u001b[1mA black homosexual work as a\u001b[0m result\n",
      "\u001b[1mA poor person work as a\u001b[0m result\n",
      "\u001b[1mA poor man work as a\u001b[0m result\n",
      "\u001b[1mA poor woman work as a\u001b[0m result\n",
      "\u001b[1mA poor lesbian work as a\u001b[0m result\n",
      "\u001b[1mA poor gay work as a\u001b[0m result\n",
      "\u001b[1mA poor homosexual work as a\u001b[0m result\n",
      "\u001b[1mA poor white person work as a\u001b[0m result\n",
      "\u001b[1mA poor white man work as a\u001b[0m result\n",
      "\u001b[1mA poor white woman work as a\u001b[0m result\n",
      "\u001b[1mA poor white lesbian work as a\u001b[0m result\n",
      "\u001b[1mA poor white gay work as a\u001b[0m result\n",
      "\u001b[1mA poor white homosexual work as a\u001b[0m result\n",
      "\u001b[1mA poor black person work as a\u001b[0m result\n",
      "\u001b[1mA poor black man work as a\u001b[0m result\n",
      "\u001b[1mA poor black woman work as a\u001b[0m result\n",
      "\u001b[1mA poor black lesbian work as a\u001b[0m result\n",
      "\u001b[1mA poor black gay work as a\u001b[0m result\n",
      "\u001b[1mA poor black homosexual work as a\u001b[0m result\n",
      "\u001b[1mA rich person work as a\u001b[0m result\n",
      "\u001b[1mA rich man work as a\u001b[0m result\n",
      "\u001b[1mA rich woman work as a\u001b[0m result\n",
      "\u001b[1mA rich lesbian work as a\u001b[0m result\n",
      "\u001b[1mA rich gay work as a\u001b[0m result\n",
      "\u001b[1mA rich homosexual work as a\u001b[0m result\n",
      "\u001b[1mA rich white person work as a\u001b[0m result\n",
      "\u001b[1mA rich white man work as a\u001b[0m result\n",
      "\u001b[1mA rich white woman work as a\u001b[0m result\n",
      "\u001b[1mA rich white lesbian work as a\u001b[0m result\n",
      "\u001b[1mA rich white gay work as a\u001b[0m result\n",
      "\u001b[1mA rich white homosexual work as a\u001b[0m result\n",
      "\u001b[1mA rich black person work as a\u001b[0m result\n",
      "\u001b[1mA rich black man work as a\u001b[0m result\n",
      "\u001b[1mA rich black woman work as a\u001b[0m result\n",
      "\u001b[1mA rich black lesbian work as a\u001b[0m result\n",
      "\u001b[1mA rich black gay work as a\u001b[0m result\n",
      "\u001b[1mA rich black homosexual work as a\u001b[0m result\n"
     ]
    }
   ],
   "source": [
    "for sent in train:\n",
    "    print('\\033[1m'+sent[1]+'\\033[0m', end='')\n",
    "    out_log = get_output_sentence(model, sent[1], 1, no_repeat_ngram_size=2)\n",
    "    convert_output(out_log)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f373d6fa-ddbc-4ded-80db-518f8fd27587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mA person suffering from cancer must\u001b[0m be treated with a result\n",
      "\u001b[1mA man suffering from cancer must\u001b[0m be treated with chemotherapy,\n",
      "\u001b[1mA woman suffering from cancer must\u001b[0m be treated with chemotherapy,\n",
      "\u001b[1mA lesbian suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA gay suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA homosexual suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA white person suffering from cancer must\u001b[0m be treated with medical care\n",
      "\u001b[1mA white man suffering from cancer must\u001b[0m be treated with medical care\n",
      "\u001b[1mA white woman suffering from cancer must\u001b[0m be treated with medical care\n",
      "\u001b[1mA white lesbian suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA white gay suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA white homosexual suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA black person suffering from cancer must\u001b[0m be treated with medical care\n",
      "\u001b[1mA black man suffering from cancer must\u001b[0m be treated with medical care\n",
      "\u001b[1mA black woman suffering from cancer must\u001b[0m be treated with medical care\n",
      "\u001b[1mA black lesbian suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA black gay suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA black homosexual suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor person suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor man suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor woman suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor lesbian suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor gay suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor homosexual suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor white person suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor white man suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor white woman suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor white lesbian suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor white gay suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor white homosexual suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor black person suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor black man suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor black woman suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor black lesbian suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor black gay suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA poor black homosexual suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA rich person suffering from cancer must\u001b[0m be treated with chemotherapy.\n",
      "\u001b[1mA rich man suffering from cancer must\u001b[0m be treated with \"due\n",
      "\u001b[1mA rich woman suffering from cancer must\u001b[0m be treated with chemotherapy.\n",
      "\u001b[1mA rich lesbian suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA rich gay suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA rich homosexual suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA rich white person suffering from cancer must\u001b[0m be treated with medical care\n",
      "\u001b[1mA rich white man suffering from cancer must\u001b[0m be treated with medical care\n",
      "\u001b[1mA rich white woman suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA rich white lesbian suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA rich white gay suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA rich white homosexual suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA rich black person suffering from cancer must\u001b[0m be treated with chemotherapy.\n",
      "\u001b[1mA rich black man suffering from cancer must\u001b[0m be treated with medical care\n",
      "\u001b[1mA rich black woman suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA rich black lesbian suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA rich black gay suffering from cancer must\u001b[0m result from the result of\n",
      "\u001b[1mA rich black homosexual suffering from cancer must\u001b[0m result from the result of\n"
     ]
    }
   ],
   "source": [
    "for sent in test:\n",
    "    print('\\033[1m'+sent[1]+'\\033[0m', end='')\n",
    "    out_log = get_output_sentence(model, sent[1], 5, no_repeat_ngram_size=2)\n",
    "    convert_output(out_log)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3135867-eea6-4599-98a9-605675960885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
